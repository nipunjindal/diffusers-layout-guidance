{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO\n",
    "1. Add datatypes\n",
    "2. Create PIP package\n",
    "3. Additional document in __call__()\n",
    "4. READme"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "def draw_box(pil_img: Image, layout_info: Dict[str, Tuple[float, float, float, float]]) -> Image:\n",
    "    # initialize width, height from pil_img\n",
    "    width, height = pil_img.size\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    for phrase, bbox in layout_info.items():\n",
    "        x_0, y_0, x_1, y_1 = bbox\n",
    "        draw.rectangle([int(x_0 * width), int(y_0 * height), int(x_1 * width), int(y_1 * height)], outline='red', width=4)\n",
    "        draw.text((int(x_0 * width) + 5, int(y_0 * height) + 5), phrase, fill=(255, 0, 0))\n",
    "    return pil_img\n",
    "\n",
    "def layout_index(prompt: str, layout_info: Dict[str, Tuple[float, float, float, float]]) -> Tuple[List[List[int]], Tuple[float, float, float, float]]:\n",
    "    prompt_list = prompt.strip('.').split(' ')\n",
    "    object_positions = []\n",
    "    for obj, bbox in layout_info.items():\n",
    "        obj_words = obj.split(' ')\n",
    "        obj_first_index = prompt_list.index(obj_words[0]) + 1\n",
    "        if len(obj_words) > 1:\n",
    "            obj_last_index = prompt_list.index(obj_words[-1]) + 1\n",
    "            obj_position = list(range(obj_first_index, obj_last_index + 1))\n",
    "        else:\n",
    "            obj_position = [obj_first_index]\n",
    "        object_positions.append((obj_position, bbox))\n",
    "\n",
    "    return object_positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/njindal/miniforge3/envs/layout-guidance/lib/python3.9/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "from layoutguidance.layout_guidance_pipeline import LayoutGuidanceStableDiffusionPipeline\n",
    "from diffusers import DPMSolverMultistepScheduler, LMSDiscreteScheduler\n",
    "import torch\n",
    "seed = 33\n",
    "\n",
    "pipe = LayoutGuidanceStableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
    "pipe = pipe.to(\"mps\")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "# pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "generator = torch.Generator(device=\"mps\").manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 77, 768]) torch.Size([1, 77, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b0002d47d7b4b3591b3b2df37a96476"
      },
      "application/json": {
       "n": 0,
       "total": 20,
       "elapsed": 0.001966714859008789,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting iteration  0 tensor(999, device='mps:0') tensor(-2.1094, device='mps:0')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DPMSolverMultistepScheduler' object has no attribute 'sigmas'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m layout_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcat\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m0.75\u001B[39m, \u001B[38;5;241m0.6\u001B[39m, \u001B[38;5;241m0.95\u001B[39m, \u001B[38;5;241m0.8\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdog\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.2\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.8\u001B[39m]}\n\u001B[1;32m      4\u001B[0m layout_info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcat\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m0.55\u001B[39m, \u001B[38;5;241m0.4\u001B[39m, \u001B[38;5;241m0.95\u001B[39m, \u001B[38;5;241m0.8\u001B[39m]}\n\u001B[0;32m----> 5\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_inference_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m             \u001B[49m\u001B[43mtoken_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m             \u001B[49m\u001B[38;5;66;43;03m# generator=generator,\u001B[39;49;00m\n\u001B[1;32m      8\u001B[0m \u001B[43m             \u001B[49m\u001B[43mbboxes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0.55\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.95\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mimages[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m image \u001B[38;5;241m=\u001B[39m draw_box(image, layout_info)\n\u001B[1;32m     10\u001B[0m display(image)\n",
      "File \u001B[0;32m~/miniforge3/envs/layout-guidance/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/build/diffusers-layout-guidance/layoutguidance/layout_guidance_pipeline.py:567\u001B[0m, in \u001B[0;36mLayoutGuidanceStableDiffusionPipeline.__call__\u001B[0;34m(self, prompt, token_indices, bboxes, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs)\u001B[0m\n\u001B[1;32m    565\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_loss(token_indices, bboxes, device) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[1;32m    566\u001B[0m grad_cond \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mgrad(loss\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m), [latents], retain_graph\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 567\u001B[0m latents \u001B[38;5;241m=\u001B[39m latents \u001B[38;5;241m-\u001B[39m grad_cond \u001B[38;5;241m*\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmas\u001B[49m[i] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    569\u001B[0m iteration \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    570\u001B[0m \u001B[38;5;28mprint\u001B[39m(loss, iteration, i)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DPMSolverMultistepScheduler' object has no attribute 'sigmas'"
     ]
    }
   ],
   "source": [
    "prompt = \"A cat playing with a ball\"\n",
    "layout_info = {\"cat\": [0.1, 0.2, 0.5, 0.8]}\n",
    "layout_info = {\"cat\": [0.75, 0.6, 0.95, 0.8], \"dog\": [0.1, 0.2, 0.5, 0.8]}\n",
    "layout_info = {\"cat\": [0.55, 0.4, 0.95, 0.8]}\n",
    "image = pipe(prompt, num_inference_steps=20,\n",
    "             token_indices=[[2]],\n",
    "             # generator=generator,\n",
    "             bboxes=[[0.55, 0.4, 0.95, 0.8]]).images[0]\n",
    "image = draw_box(image, layout_info)\n",
    "display(image)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
